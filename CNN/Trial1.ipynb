{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as mpl\n",
    "from keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.00392157\n",
      "  0.         0.         0.         0.         0.16078431 0.7372549\n",
      "  0.40392157 0.21176471 0.18823529 0.16862745 0.34117647 0.65882353\n",
      "  0.52156863 0.0627451  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.00392157 0.         0.\n",
      "  0.         0.19215686 0.53333333 0.85882353 0.84705882 0.89411765\n",
      "  0.9254902  1.         1.         1.         1.         0.85098039\n",
      "  0.84313725 0.99607843 0.90588235 0.62745098 0.17647059 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.05490196\n",
      "  0.69019608 0.87058824 0.87843137 0.83137255 0.79607843 0.77647059\n",
      "  0.76862745 0.78431373 0.84313725 0.8        0.79215686 0.78823529\n",
      "  0.78823529 0.78823529 0.81960784 0.85490196 0.87843137 0.64313725\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.7372549\n",
      "  0.85882353 0.78431373 0.77647059 0.79215686 0.77647059 0.78039216\n",
      "  0.78039216 0.78823529 0.76862745 0.77647059 0.77647059 0.78431373\n",
      "  0.78431373 0.78431373 0.78431373 0.78823529 0.78431373 0.88235294\n",
      "  0.16078431 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.2        0.85882353\n",
      "  0.78039216 0.79607843 0.79607843 0.83137255 0.93333333 0.97254902\n",
      "  0.98039216 0.96078431 0.97647059 0.96470588 0.96862745 0.98823529\n",
      "  0.97254902 0.92156863 0.81176471 0.79607843 0.79607843 0.87058824\n",
      "  0.54901961 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.45490196 0.88627451\n",
      "  0.80784314 0.8        0.81176471 0.8        0.39607843 0.29411765\n",
      "  0.18431373 0.28627451 0.18823529 0.19607843 0.17647059 0.2\n",
      "  0.24705882 0.44313725 0.87058824 0.79215686 0.80784314 0.8627451\n",
      "  0.87843137 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.78431373 0.87058824\n",
      "  0.81960784 0.79607843 0.84313725 0.78431373 0.         0.2745098\n",
      "  0.38431373 0.         0.40392157 0.23137255 0.26666667 0.27843137\n",
      "  0.19215686 0.         0.85882353 0.80784314 0.83921569 0.82352941\n",
      "  0.98039216 0.14901961 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.96862745 0.85490196\n",
      "  0.83137255 0.82352941 0.84313725 0.83921569 0.         0.99607843\n",
      "  0.95294118 0.54509804 1.         0.68235294 0.98431373 1.\n",
      "  0.80392157 0.         0.84313725 0.85098039 0.83921569 0.81568627\n",
      "  0.8627451  0.37254902 0.         0.        ]\n",
      " [0.         0.         0.         0.17647059 0.88627451 0.83921569\n",
      "  0.83921569 0.84313725 0.87843137 0.80392157 0.         0.16470588\n",
      "  0.1372549  0.23529412 0.0627451  0.06666667 0.04705882 0.05098039\n",
      "  0.2745098  0.         0.74117647 0.84705882 0.83137255 0.80784314\n",
      "  0.83137255 0.61176471 0.         0.        ]\n",
      " [0.         0.         0.         0.64313725 0.92156863 0.83921569\n",
      "  0.82745098 0.8627451  0.84705882 0.78823529 0.20392157 0.27843137\n",
      "  0.34901961 0.36862745 0.3254902  0.30588235 0.2745098  0.29803922\n",
      "  0.36078431 0.34117647 0.80784314 0.81176471 0.87058824 0.83529412\n",
      "  0.85882353 0.81568627 0.         0.        ]\n",
      " [0.         0.         0.         0.41568627 0.73333333 0.8745098\n",
      "  0.92941176 0.97254902 0.82745098 0.77647059 0.98823529 0.98039216\n",
      "  0.97254902 0.96078431 0.97254902 0.98823529 0.99215686 0.98039216\n",
      "  0.98823529 0.9372549  0.78823529 0.83137255 0.88235294 0.84313725\n",
      "  0.75686275 0.44313725 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.06666667\n",
      "  0.21176471 0.62352941 0.87058824 0.75686275 0.81568627 0.75294118\n",
      "  0.77254902 0.78431373 0.78431373 0.78431373 0.78431373 0.78823529\n",
      "  0.79607843 0.76470588 0.82352941 0.64705882 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.18431373 0.88235294 0.75294118 0.83921569 0.79607843\n",
      "  0.80784314 0.8        0.8        0.80392157 0.80784314 0.8\n",
      "  0.83137255 0.77254902 0.85490196 0.41960784 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.00392157 0.02352941\n",
      "  0.         0.18039216 0.83137255 0.76470588 0.83137255 0.79215686\n",
      "  0.80784314 0.80392157 0.8        0.80392157 0.80784314 0.8\n",
      "  0.83137255 0.78431373 0.85490196 0.35686275 0.         0.01176471\n",
      "  0.00392157 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157\n",
      "  0.         0.04313725 0.77254902 0.78039216 0.80392157 0.79215686\n",
      "  0.80392157 0.80784314 0.8        0.80392157 0.81176471 0.8\n",
      "  0.80392157 0.80392157 0.85490196 0.30196078 0.         0.01960784\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.01176471\n",
      "  0.         0.00784314 0.74901961 0.77647059 0.78823529 0.80392157\n",
      "  0.80784314 0.80392157 0.80392157 0.80784314 0.81960784 0.80784314\n",
      "  0.78039216 0.81960784 0.85882353 0.29019608 0.         0.01960784\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00784314\n",
      "  0.         0.         0.7372549  0.77254902 0.78431373 0.81176471\n",
      "  0.81176471 0.8        0.81176471 0.81176471 0.82352941 0.81568627\n",
      "  0.77647059 0.81176471 0.86666667 0.28235294 0.         0.01568627\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00784314\n",
      "  0.         0.         0.84313725 0.77647059 0.79607843 0.80784314\n",
      "  0.81568627 0.80392157 0.81176471 0.81176471 0.82352941 0.81568627\n",
      "  0.78431373 0.79215686 0.87058824 0.29411765 0.         0.01568627\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157\n",
      "  0.         0.         0.83137255 0.77647059 0.81960784 0.80784314\n",
      "  0.81960784 0.80784314 0.81568627 0.81176471 0.82745098 0.80784314\n",
      "  0.80392157 0.77647059 0.86666667 0.31372549 0.         0.01176471\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157\n",
      "  0.         0.         0.8        0.78823529 0.80392157 0.81568627\n",
      "  0.81176471 0.80392157 0.82745098 0.80392157 0.82352941 0.82352941\n",
      "  0.81960784 0.76470588 0.86666667 0.37647059 0.         0.01176471\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157\n",
      "  0.         0.         0.79215686 0.78823529 0.80392157 0.81960784\n",
      "  0.81176471 0.80392157 0.83529412 0.80784314 0.82352941 0.81960784\n",
      "  0.82352941 0.76078431 0.85098039 0.41176471 0.         0.00784314\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157\n",
      "  0.         0.         0.8        0.8        0.80392157 0.81568627\n",
      "  0.81176471 0.80392157 0.84313725 0.81176471 0.82352941 0.81568627\n",
      "  0.82745098 0.75686275 0.83529412 0.45098039 0.         0.00784314\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.8        0.81176471 0.81176471 0.81568627\n",
      "  0.80784314 0.80784314 0.84313725 0.82352941 0.82352941 0.81176471\n",
      "  0.83137255 0.76470588 0.82352941 0.4627451  0.         0.00784314\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157\n",
      "  0.         0.         0.77647059 0.81568627 0.81568627 0.81568627\n",
      "  0.8        0.81176471 0.83137255 0.83137255 0.82352941 0.81176471\n",
      "  0.82745098 0.76862745 0.81176471 0.4745098  0.         0.00392157\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157\n",
      "  0.         0.         0.77647059 0.82352941 0.81176471 0.81568627\n",
      "  0.80784314 0.81960784 0.83529412 0.83137255 0.82745098 0.81176471\n",
      "  0.82352941 0.77254902 0.81176471 0.48627451 0.         0.00392157\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.6745098  0.82352941 0.79607843 0.78823529\n",
      "  0.78039216 0.8        0.81176471 0.80392157 0.8        0.78823529\n",
      "  0.80392157 0.77254902 0.80784314 0.49803922 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.7372549  0.86666667 0.83921569 0.91764706\n",
      "  0.9254902  0.93333333 0.95686275 0.95686275 0.95686275 0.94117647\n",
      "  0.95294118 0.83921569 0.87843137 0.63529412 0.         0.00784314\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157\n",
      "  0.         0.         0.54509804 0.57254902 0.50980392 0.52941176\n",
      "  0.52941176 0.5372549  0.49019608 0.48627451 0.49019608 0.4745098\n",
      "  0.46666667 0.44705882 0.50980392 0.29803922 0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "minst = tf.keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = minst.load_data()\n",
    "# print(x_train.shape)\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  model = tf.keras.models.Sequential()\n",
    "  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
    "  model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu'))\n",
    "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "  model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
    "  model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n",
    "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
    "  model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n",
    "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "  model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  model.add(tf.keras.layers.Dense(256))\n",
    "  model.add(tf.keras.layers.Activation('elu'))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(10))\n",
    "  model.add(tf.keras.layers.Activation('softmax'))\n",
    "  return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85c033c787bf783fc9ad8abcec0d23c99391b25b7517a737387b34690baa5a78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
